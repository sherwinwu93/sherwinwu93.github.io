[BLANK_AUDIO] We end in the last lecture. By looking at how we can evolve moral
sentiment, through genetic relatives. Through, kin selection.

But, what about kindness to non-relatives?
So... Humans at least, and probably other
creatures. Are not only altruistic to those, who
we're related to. We're also altruistic to those we aren't
related to, those we hang out with. People we, we're in constant interaction
with. arguably, this may be somewhat
controversial. But vampire bats might do the same. So, the may not only regurgitate blood
into the mouths of their offspring. But, also, in, in the mouths of other
vampire bats who live in their cave. And then, they may get involved in a sort
of reciprocal relationship. And this is, the, the explanation for
where this kindness. To to others, others, who you aren't related to.

Is sometimes described as reciprocal
altruism. And this is a theory developed in it's
most. by, by many scholars and including, Robert
Trevors. An idea is, if you scratch my back, I'll
scratch yours. The idea is that we could all benefit, if
we help one another. If we if for instance I would benefit if you watch my kids, when I
go. In return, I'll watch your kids, when
you're off. And, you could see, how in any society,
any community, any group. Everybody is better off, if you form these
cycles of mutual benefit.

Now, there's, of course, a problem with
this. And, it's a problem we saw in the last
lecture. When we talked about indiscriminate
altruists. Which is that, if we are just kind. Without recip, without expecting any reciprocation, without expecting anything
back. This it will never work, because cheaters
could emerge, free riders. People who will accept your help, but not
help you. And, if the free riders have an advantage. Then, the genes that give rise to
kindness, would get wiped out of the population.
They'd be mal adaptive. They'd be beaten out, by individuals, who
accept kindness but don't give it.
So, the project that needs to be explained
then. Is how can, sense we know we get into these reciprocally altruistic
relationships. We know we get along with people, we, we,
we're kind to those around us.

How could this evolve? How could this evolve, under the concern,
that people could cheat and free ride?
Now, one way to think about this. Is through a classic game, a classic
problem. It's known as the prisoner's dilemma. The prisoner's dilemma has been studied, a
million times. By economists, by philosophers, by
biologists, certainly, by psychologists. Because it's a nice way exploring certain
features of human nature. And, asking how these features of human
nature have evolved. It's a wonderful tool for. Thinking about the question we're
struggling with now. Which is how can in a sort of, through the
amoral process of natural selection. How can kindness emerge, even kindness to
non kin?

So, here's how the prisoners dilemma
works. Imagine you rob a bank with somebody, and
you, you hide out. You have the money. And then, you're arrested. You and your partner are arrested. You're prisoner one, you're partner is
prisoner two. And, you know, they don't actually have
tremendously good evidence. That you did it.
You know this. They, they could, they could... They could keep you in prison under a
lesser charge. But, whether or not you did the robbery. They're not sure.
So, you're sitting in the. Imagine 100 TV shows, 100 movies. You're sitting in that room, the
interrogation room, with that mirror. But, it's not really a mirror, they can
see you through it. And, police officer walks in and sits, and
says, I'm going to make you a deal. I know you're friends with this other guy
we have. We have. He's in the other room. But here's the deal.
If you defect, that is, you confess to the whole crime
and say your partner did it, and agree to testify
against your partner. Defect against your partner, testify
against your partner, you will go free. Your partner, your partner will get life
in prison. That's the deal, I'm offering you.
Let me tell you something though. My partner, not as patient a man as I am. My partner is in the next room, and he's
talking to your friend. And, he's making your friend, exactly the
same offer. In fact, in this imaginary case the police officer might, helpfully, bring out a
sheet of paper. That shows you the different options. So, if you and your partner both cooperate
with each other. By that means, is you each say, I'm not saying a word. All they can do is get you on the lesser charge, and you'll each get one
year in prison. That's the cooperate, cooperate thing, you
see on the top left. On the other hand if you, your player 1. If you if you cooperate with your partner
and you don't say anything. But your partner squeals on you. Defects, you will go to prison for the
rest of your life. And, your partner will walk. Correspondingly, if your partner doesn't
squeal on you. But, you squeal on him, you defect, you
walk. And, he goes to prison for the rest of his
life. If you both defect on each other, you both
go to prison for 10 years.

So, you're looking at this sheet of paper,
and you're thinking about your options. And, you notice a certain things.
So, first thing you notice that. The best thing any individual can do is
defect, while the other person cooperates. So, I'm sitting there, I'm saying, look
the best thing for you is to say. I'll tell you, it's all my partners idea. I'll give you all the evidence you need
against him. I'll testify against him.
Then, I get to go home. The worst thing is, if I say. My partner's, my friend.
I am never testifying against. I am shutting my mouth. And, he defects.
Then, he goes home. You spend the rest of your life in prison. The best overall solution for both of you,
is if you both cooperate, together. Neither of you says a word. And, the worst, is if you both defect.

And, it turns out this, this array of
options, has certain interesting features. The first one, is regardless of what that
other guy does. Regardless of what Prisoner 2, your
partner does, it pays to defect. So, if he cooperates. So, he says, I'm not going to squeal
against my friend. Your best option is to defect, is to say
he did it all, and you get to leave. On the other hand, if he squeals against
you. You're best option is to squeal against
him, back. Then, instead of life in prison, you just
get a serious long stay in prison. But, even though it's rational for each
person to defect, no matter what the other one
does. If both players defect, both are worse off.

Now, this might seem like a crazy and
bizarre and arbitrary sort of example, with, with, all
fixed up and everything. But, it turns out that prisoner's dilemma
show up, all over daily life. All over interactions with other people. I'll give you a few examples, just to
illustrate this. Imagine my spouse and I, decide to get a
divorce. We decide to break up.
We've been together many years, we're going to break up. And we're not talking to each other now,
but we each face an option. The option is, we could cooperate with
each other. And, what that means is, amicably split
our possessions. Say okay, you take half, I take half.
They even up. And, you know, if we did that, we'd both
do okay. But now, it occurs to me, occurs to me, that I could defect.
So, I could, get a lawyer. And, what I mean, so I get, all of a
sudden, she's in cooperating mode. Oh we'll cooperate, I'll get a killer
divorce lawyer. And, I will, a killer divor-, I'll get
everything. And since, she didn't think to get a
lawyer, she'll get nothing. It's best for me. I defect, I get a lawyer, she cooperates.
It also occurs to me, even if I say, oh, I would never do
that. That occurs to me. You know, she might do that. And, I would lose everything, and she'd
get everything. And, of course, she is thinking exactly
what I'm thinking. So, we have to get lawyers. We both get divorce lawyers.
We have a huge battle. We pay the lawyers and, and we both do
pretty, badly. It would've been better off for us, if we
both cooperated with each other. But, because of the fear of being destroyed, if the other
one defected. As well as the temptation to defect and
destroy the other. We both move into a situation, which isn't
as good, as if we could have cooperated.

Imagine you're a country, you're country
A, there's country B. You have all, you have some degree of a,
you have a budget, you have money. Do you spend the money making your Your
population happy. Giving them health care, and food, and
roller coasters, and everything? Or, do you spend the money preparing for
war, to invade the other country? Well, imagine both countries invest in
peace. That's okay, they both do okay, their
happy. But, this is a prisoners dilemma. Because, if country A invests in war, and
country B invests in peace. Then, country A could avoid, I'm sorry
country A could invade country B. Get everything. And, country B would lose everything. Correspondingly, of course, if country B
invested in war. And, country A in peace.
B could get everything, and A would loose everything. The logic is very clear then, both
countries had to prepare for war. And, both do pretty badly. It would have been better off, if they
could both prepare for peace. But, they had no choice.

One final example suppose I want to buy
drugs. Suppose, I, I wouldn't want to do this,
but suppose I wanted to. And, it's illegal, so, and it's important
for the example. So, suppose I wanted to buy drugs.
I have a lot of money, but I don't have any drugs. And, I hear from this person and, and, he
has a lot of drugs and no money. So, we get in touch with each other, and
we say. Let's meet in this dark alley, at two in
the morning. And, I'll bring the money, and he'll bring
the drugs. So, what's the optimal solution for both
of us? Well, we go to the alley.
I give him the money, he takes the money. He gives me back the drugs. I walk away with the drugs, he walks away
with the money. Okay it's good, good trade. But, then, something occurs to me. What occurs to me is, if I bring a gun, to
this alley. I could keep my money and get his drugs,
which is very good for me. It's very tempting, all of a sudden.
You could defect. Then, something else occurs to me.
If he came to the alley with a gun. And, I didn't have a gun. He would take my money and walk home with
his drugs. That's very bad for me. The logic then, it, it, it is very strong. We should both bring guns. The one who doesn't bring a gun is going to be screwed, if the other one brings a
gun. We both bring guns. It's not as good.
We'd be better off, if neither one of us brought guns.
We both bring them. But, we were both forced to this bad
choice. By the logic of the prisoners' dilemma.

So, this seems terrible. It seems like a situation, which shows up
over and over again, in the real world. Where brute logic, sort of, forces you to
a conclusion that is less than optimal, for everybody.
You know, where both prisoners end up going to prison for a
long time. Or, countries go to war. Where where spouses have horrific divorce
battles. And, I don't get my, my drugs, but
instead, get into a gunfight.

So, what to do? Well, in all of these cases, we're
imagining a one shot deal. A one shot interaction.
What if individuals could play each other, over, and over, and
over again? How would that change things? So, what if it's not life and death, but
you gain something and lose something. But, you can play people over and over
again? How would that change things? Well, it turns out that, one way to
explore this was, was developed the 1980s. It was a famous competition. And, the idea would be, people would
create computer programs. That play prisoner dilemma games. And, the prisoner dilemma games, would
play against each other. I'm sorry, the programs would play against
each other. And, the question is, who would be the
winner. What strategy would lead to the most
benefit, if you have to play prisoner dilemma games over, and over, and over, again, with other
individuals? And, 63 programs competed. And, the winner, was one developed by the
scientist, Anatol Rapoport.
And, it's called Tit-for-Tat. And, what was amazing about this is. Many of the programs were very
complicated. Random strategies, all sorts of weird
complexities. That the program that Rapoport presented
was extremely simple. It, basically, had, just two rules. The first time you meet a new program,
cooperate. After that, do on each trial, what a
program did, on a previous trial. So, think about it, that a bit and see why
this is smart. Imagine you and I were to play a
prisoner's dilemma game. And, we had to play it 100 times. And, the question is, how much would we
each gain? And, you could see, there's a lot of
cleverness in tit for tat. So, it's nice, it starts off friendly. I say, I'm starting off cooperating.
If you cooperate back, we're going to make ourselves a lot
of money. But, it's not a sucker. If you screw me, if you defect on game
one. I'm going to defect back, on game two. So, it's not going to, it's not going to
be exploited. The world's worst prisoners' dilemma
program. Would always cooperate. because, then, people would just defect,
and there would always be a sucker. This is not a sucker. But, it's forgiving.
So, we're defecting. You know, you defect on me, I defect on
you. Defect, defect defect. Then, you decide to be nice and you say,
okay, I want to cooperate this time. Then, the next game, I'll be nice right
back. And, it's transparent, what I'm doing is
not rocket science. You can see what I'm doing. And, if you're a smart program or a smart
person, you could figure out how to work together
for mutual gain. Now, a lot has happened since the 1980s. And, there are more clever and more
complicated programs for. Playing the Prisoner's Dilemma and
interacting.

But, the insights of this sort of tit for
tat logic seem to capture, in a rough sense,
human psychology. And, the human psychology of how we
interact with one another. So, we can think about now, some of the
emotions. Including, the moral emotions. And, how their emotions might guide us to do an interaction. Not unlike Tit for Tat, which could turn
out for mutual gain. We feel gratitude and liking, for those
who cooperate with us. Indeed, this feelings makes us want to
cooperate with them. That's an, in a, in a, in an extremely
simple way. A lot of what friendship is about. You're nice to me, I feel I want to be
nice to you, and we get along. We have this mutual trading back and
forth. We feel anger and distrust towards those
who betray us. Which, motivates us to betray them, or
avoid them in the future. You defect, you screw me, you, you put me
in a bad position? The next time we play, I'm going to do
that you. Or, in some other games, where, where, I
would have the option, I won't play with you
anymore. And, we feel guilt, when we betray
somebody, who we cooperate with. And, that motivates us to behave better in
the future. So, this gets us a bit far from Tit for
Tat. But, if I defected on you, and you were nice to me, I'd feel
really bad. And, I would try to make amends in the
future.

And, and Trivers has argued, that the
logic of the solution to the prisoner's dilemma
game. The logic to how people can interact over
multiple times and lead to mutual benefit, has led to the
structuring of our moral emotions. That is, we are naturally inclined in our
sentiments to act towards others, as if we are going to play repeated game
of social interactions. And, our moral emotions are tailored. So as, so that... To guide us to behave in such a way. That these actions, will be mutually
beneficial. But, also to have an eye out, so that we.
We can be discriminate altruists. We are nice to those, who are nice to us. We are not nice to those, who are not nice
to us.

In the last two lectures, we've talked a
bit about evolution. And, we've talked about the, sort of,
mainstream evolutionary theories. As to have some moral sentiments.
Could, possibly, be wired into us. We talked about kin selection. And then, we talked about reciprocal
altruism. But, at this point, we haven't actually
argued it's true. We haven't given any evidence that people actually do have these sentiments wired
into them. As opposed to having them emerge, through
the course of development. And, we don't have any evidence from other
sources, like looking at other creatures. So, the next two lectures are going to
fill this gap. The next lecture, which is a long one. And, a very, very good one. Is by my colleague and my friend Professor
Laurie Santos. It is a classroom lecture, she presented,
when I gave this morality course as as a class.
At Yale. And so, you'll see her on the podium,
giving her lecture. And, I you know. And, and the video was going to include my introduction to her, I wont repeat in
here. But, what it is, is it will give you a
feeling, for what we know. The strengths and limitations of morality
in non human primates. Then, after this, my next lecture is
going to to be a very different domain. It's going to ask to what extent are these moral sentiments and moral
capacities present in human infants. And, this is a topic, which, I think, is
also quite interesting. [MUSIC]
